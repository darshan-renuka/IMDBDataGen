{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb54357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c0ebf3",
   "metadata": {},
   "source": [
    "# Read 500000 records from MergedData-APr4 and pick 50000 unique movies from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e210ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FinalMergedIMDBMovieData-4Apr.csv contains data in the following format -\n",
    "#Unnamed: 0\ttconst\ttitleType\ttitle\toriginalTitle\tisAdult\tstartYear\tendYear\truntimeMinutes\tgenres\taverageRating\tnumVotes\tordering\tnconst\tcategory\tjob\tcharacters\n",
    "#0\t0\ttt0000001\tshort\tCarmencita\tCarmencita\t0\t1894\t\\N\t1\tDocumentary,Short\t5.7\t1966.0\t1.0\tnm1588970\tself\t\\N\t[\"Self\"]\n",
    "# FinalMergedIMDBMovieData-4Apr.csv is the output of imdb_ED_script.ipynb\n",
    "\n",
    "i=0\n",
    "movie_list = []\n",
    "chunk_size = 50000\n",
    "total_req_size = 550000\n",
    "for chunk in pd.read_csv('FinalMergedIMDBMovieData-4Apr.csv', low_memory=False, chunksize=chunk_size):\n",
    "    for row, data in chunk.iterrows():\n",
    "        movie_list.append(data)\n",
    "        i+=1\n",
    "    if i>total_req_size:\n",
    "        break\n",
    "imdb_df = pd.DataFrame(movie_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a35e635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>title</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>ordering</th>\n",
       "      <th>nconst</th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "      <th>characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>short</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>0</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Documentary,Short</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nm1588970</td>\n",
       "      <td>self</td>\n",
       "      <td>\\N</td>\n",
       "      <td>[\"Self\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>short</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>0</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Documentary,Short</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>nm0005690</td>\n",
       "      <td>director</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>short</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>0</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Documentary,Short</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nm0374658</td>\n",
       "      <td>cinematographer</td>\n",
       "      <td>director of photography</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0000002</td>\n",
       "      <td>short</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>Animation,Short</td>\n",
       "      <td>5.8</td>\n",
       "      <td>263.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nm0721526</td>\n",
       "      <td>director</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0000002</td>\n",
       "      <td>short</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>Animation,Short</td>\n",
       "      <td>5.8</td>\n",
       "      <td>263.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>nm1335271</td>\n",
       "      <td>composer</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     tconst titleType                   title  \\\n",
       "0           0  tt0000001     short              Carmencita   \n",
       "1           1  tt0000001     short              Carmencita   \n",
       "2           2  tt0000001     short              Carmencita   \n",
       "3           3  tt0000002     short  Le clown et ses chiens   \n",
       "4           4  tt0000002     short  Le clown et ses chiens   \n",
       "\n",
       "            originalTitle  isAdult  startYear endYear runtimeMinutes  \\\n",
       "0              Carmencita        0       1894      \\N              1   \n",
       "1              Carmencita        0       1894      \\N              1   \n",
       "2              Carmencita        0       1894      \\N              1   \n",
       "3  Le clown et ses chiens        0       1892      \\N              5   \n",
       "4  Le clown et ses chiens        0       1892      \\N              5   \n",
       "\n",
       "              genres  averageRating  numVotes  ordering     nconst  \\\n",
       "0  Documentary,Short            5.7    1966.0       1.0  nm1588970   \n",
       "1  Documentary,Short            5.7    1966.0       2.0  nm0005690   \n",
       "2  Documentary,Short            5.7    1966.0       3.0  nm0374658   \n",
       "3    Animation,Short            5.8     263.0       1.0  nm0721526   \n",
       "4    Animation,Short            5.8     263.0       2.0  nm1335271   \n",
       "\n",
       "          category                      job characters  \n",
       "0             self                       \\N   [\"Self\"]  \n",
       "1         director                       \\N         \\N  \n",
       "2  cinematographer  director of photography         \\N  \n",
       "3         director                       \\N         \\N  \n",
       "4         composer                       \\N         \\N  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique movies\n",
    "# imdb_df = imdb_df.drop(columns=['Unnamed: 0'])\n",
    "print(imdb_df.title.nunique())\n",
    "imdb_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c976462",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.tconst.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.to_csv('FinalMergedIMDBMovieData-4Apr_Subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feabd164",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_group = imdb_df.groupby('title').agg({'tconst':['nunique', 'unique']}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = t_group[t_group[('tconst', 'nunique')]>1]\n",
    "len(temp)\n",
    "temp.to_csv('title_with_more_than_one_id.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd2fa3d",
   "metadata": {},
   "source": [
    "# Generate random userIDs - 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc1bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = []\n",
    "for i in range(100000,300001):\n",
    "    user_list.append('ID'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "(user_list)[3123]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1bc26c",
   "metadata": {},
   "source": [
    "# Generate random user-movie interaction data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca41eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = list(imdb_df.title.unique())\n",
    "len(title_list) * 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_seed = 414\n",
    "max_data_size = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f95d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users with no watch counts and movies with no watch counts - 10% of users, 5% of movies\n",
    "no_watch_user_count = len(user_list) * 0.1\n",
    "no_watch_movie_count = len(title_list) * 0.05\n",
    "user_list_null = user_list[0:no_watch_user_count]\n",
    "title_list_null = title_list[0:no_watch_movie_count]\n",
    "\n",
    "user_list = user_list[no_watch_user_count:]\n",
    "title_list = title_list[no_watch_movie_count:]\n",
    "\n",
    "print(len(user_list))\n",
    "print(len(user_list_null))\n",
    "print(len(title_list))\n",
    "print(len(title_list_null))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da82830d",
   "metadata": {},
   "source": [
    "# 1. Selecting a particular user and populating the movies for the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4056fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Pick random users from user_list. This can be varied with the user_list_size variable below.\n",
    "# 2. Set a max limit for number of movies a user can watch. Can be set with the max_data_size variable\n",
    "# 3.For each unique user, generate permutations of various movies watched by altering the user_list_size and max_data_size variables.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PIck random users from user_list\n",
    "# 2. Set max_data_size\n",
    "random_seed = 675\n",
    "max_data_size = 1600\n",
    "user_list_size = 3000\n",
    "user_list_temp = []\n",
    "random_indices = list(np.random.randint(low=0, high=len(user_list),size=user_list_size))\n",
    "for i in range(0,len(random_indices)):\n",
    "    user_list_temp.append(user_list[random_indices[i]])\n",
    "len(user_list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aacf0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(random_seed)\n",
    "final_df = pd.DataFrame(columns= ['user_id', 'title', 'rating', 'interest'])\n",
    "total_size = 0\n",
    "\n",
    "# 3. For each unique user, get permutation combination of various movies\n",
    "for user in user_list_temp:\n",
    "    temp_df = pd.DataFrame(columns= ['user_id', 'title', 'rating', 'interest'])\n",
    "    data_size = random.randint(1,max_data_size)\n",
    "    total_size += data_size\n",
    "    #print('Generated ', str(data_size), ' new data points for user - ', str(user))\n",
    "    #for i in range(1, data_size):\n",
    "    temp_df.title = np.random.choice(title_list, size=data_size)\n",
    "    temp_df.rating = list(np.random.randint(low=1, high=5,size=data_size))\n",
    "    temp_df.interest = list(np.random.rand(data_size))\n",
    "    temp_df.user_id = np.random.choice([user], size=data_size) # Assigning same userid to all records in a loop. \n",
    "    \n",
    "    final_df = pd.concat([temp_df, final_df], ignore_index=True, axis=0)\n",
    "print('Total rows generated - ', str(total_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9776ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total rows generated - ', str(total_size))\n",
    "# write each chunk of generated data to a csv.\n",
    "final_df.to_csv('imdb_generated_data-7.csv')\n",
    "\n",
    "# RUn the above cell as required by changing the following params to get different results - \n",
    "# random_seed = 675\n",
    "# max_data_size = 1600\n",
    "# user_list_size = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e97e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.user_id.nunique())\n",
    "final_df.title.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8120271",
   "metadata": {},
   "source": [
    "# 2. Selecting a particular movie and populating the users for the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick random titles \n",
    "# TODO: Vary low param of np.random.randint() - \n",
    "# 1.start by keeping low and high param values very close. keep Descreasing low param value and iterate for multiple steps.\n",
    "# Do the same for low and high params - data_size = random.randint(max_data_size-2000,max_data_size) 5 cells below (actual generation of data cell) \n",
    "\n",
    "random_seed = 890\n",
    "max_data_size = 6000\n",
    "title_list_size = 200\n",
    "title_list_temp = []\n",
    "random_indices = list(np.random.randint(low=int(len(title_list)/10), high=len(title_list),size=title_list_size))\n",
    "for i in range(0,len(random_indices)):\n",
    "    title_list_temp.append(title_list[random_indices[i]])\n",
    "len(title_list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b288fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental -\n",
    "# Generate lots of movies(1000-1200 movies) with high user voew counts (user view counts > 4500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea0a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Experimental - Increasing user counts of movies for large viewership\n",
    "# Curent status - Due to large u=number of movies, user counts for movies are concentrated on the lower side, \n",
    "# i.e, movies have low user count between - (1-3000 users per movie)\n",
    "# Tryin to increase the user counts in the 4500-5500 range\n",
    "df = pd.read_csv('imdb_subset_generated_data_merged.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_counts = df.groupby('title').agg({'user_id':['count','nunique']}).reset_index().sort_values(('user_id', 'nunique'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538510db",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_title_list = title_counts[title_counts[('user_id', 'nunique')]>=4500]\n",
    "high_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ede08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick random titles \n",
    "# TODO: Vary low param of np.random.randint() - \n",
    "# 1.start by keeping low and high param values very close. keep Descreasing low param value and iterate for multiple steps.\n",
    "# Do the same for low and high params - data_size = random.randint(max_data_size-2000,max_data_size) 5 cells below (actual generation of data cell) \n",
    "\n",
    "random_seed = 890\n",
    "max_data_size = 6000\n",
    "title_list_size = 200\n",
    "title_list_temp = []\n",
    "random_indices = list(np.random.randint(low=int(len(title_list)/10), high=len(title_list),size=title_list_size))\n",
    "for i in range(0,len(random_indices)):\n",
    "    title_list_temp.append(title_list[random_indices[i]])\n",
    "len(title_list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04201ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(random_seed)\n",
    "final_df = pd.DataFrame(columns= ['user_id', 'title', 'rating', 'interest'])\n",
    "\n",
    "total_size = 0\n",
    "print(final_df.shape)\n",
    "# 1. For each unique user, get permutation combination of various movies\n",
    "for title in title_list_temp:\n",
    "    temp_df = pd.DataFrame(columns= ['user_id', 'title', 'rating', 'interest'])\n",
    "    data_size = random.randint(max_data_size-1000,max_data_size)\n",
    "    total_size += data_size\n",
    "    print('Generated ', str(data_size), ' new data points for title - ', str(title))\n",
    "    #for i in range(1, data_size):\n",
    "    temp_df.title = [title] * data_size\n",
    "    temp_df.rating = list(np.random.randint(low=1, high=5,size=data_size))\n",
    "    temp_df.interest = list(np.random.rand(data_size))\n",
    "    temp_df.user_id = np.random.choice(user_list, size=data_size)\n",
    "    \n",
    "    final_df = pd.concat([temp_df, final_df], ignore_index=True, axis=0)\n",
    "print('Total rows generated - ', str(total_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e424fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('imdb_generated_data-9_high_user_count.csv')\n",
    "# RUn the above cell as required by changing the following params to get different results - \n",
    "# random_seed = 675\n",
    "# max_data_size = 1600\n",
    "# title_list_size = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.user_id.nunique())\n",
    "final_df.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29149334",
   "metadata": {},
   "source": [
    "# Data validation - Check if the generated data follows any kind of uniform distribution, if so delete that chunk of data|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f98ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('imdb_generated_data-1.csv')\n",
    "df2 = pd.read_csv('imdb_generated_data-2.csv')\n",
    "df3 = pd.read_csv('imdb_generated_data-3.csv')\n",
    "df4 = pd.read_csv('imdb_generated_data-4.csv')\n",
    "df5 = pd.read_csv('imdb_generated_data-5.csv')\n",
    "df6 = pd.read_csv('imdb_generated_data-6.csv')\n",
    "df7 = pd.read_csv('imdb_generated_data-7_9357_unique_titles.csv')\n",
    "df8 = pd.read_csv('imdb_generated_data-8_high_user_count.csv')\n",
    "df9 = pd.read_csv('imdb_generated_data-9_high_user_count.csv')\n",
    "df = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('generated_data/imdb_subset_generated_data_merged_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f06eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4fb344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.user_id.nunique())\n",
    "df.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618cdb76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_counts = final_df.groupby('title').agg({'user_id':['count','nunique']}).reset_index()\n",
    "title_counts.to_csv('title_watch_counts_imdb_high_user_count_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2205e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts = final_df.groupby('user_id').agg({'title':['count','nunique']}).reset_index()\n",
    "user_counts.to_csv('user_watch_counts_imdb_high_user_count_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e526fafa",
   "metadata": {},
   "source": [
    "# Merge the additional movie info to all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edcd6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('generated_data/imdb_subset_generated_data_merged_final.csv')\n",
    "print(df.columns)\n",
    "# imdb_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce43f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "imdb_df.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a65eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1216232",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df['crew_job'] = None\n",
    "imdb_df['character_name'] = None\n",
    "imdb_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f4b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df = imdb_df[imdb_df['title'].isin(df.title.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(merged_df.shape)\n",
    "imdb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate all crew info to a single row for each movie of the format - \n",
    "# crew_job ->[{'nconst1':'category'}, {'nconst12':'category'}, ....]\n",
    "# character_name -> [{'nconst1':'char_name'}, {'nconst12':'char_name'}, ....]\n",
    "# Remove following columns  - ordering, nconst, category, job, category, characters, tconst\n",
    "\n",
    "imdb_df_temp = imdb_df.loc[0:10, :]\n",
    "title_group = imdb_df.groupby('title')\n",
    "# temp_df = pd.DataFrame(columns=['crew_job', 'character_name'])\n",
    "crew_job = []\n",
    "crew_name = []\n",
    "title = []\n",
    "title_type =[]\n",
    "start_year = []\n",
    "end_year = []\n",
    "runtime = []\n",
    "genres = []\n",
    "avg_rating = []\n",
    "num_votes = []\n",
    "\n",
    "for key, group in title_group:\n",
    "    c_job = []\n",
    "    c_name = []   \n",
    "#     print(group)\n",
    "    for row, data in group.iterrows():\n",
    "        if data['category'] != '\\\\N':\n",
    "            c_job.append({data['nconst']:data['category']})\n",
    "        if data['characters'] != '\\\\N':\n",
    "            c_name.append({data['nconst']:data['characters']})\n",
    "            \n",
    "    crew_job.append(c_job)\n",
    "    crew_name.append(c_name)\n",
    "    title.append(group.reset_index().loc[0,'title'])\n",
    "    title_type.append(group.reset_index().loc[0,'titleType'])\n",
    "    start_year.append(group.reset_index().loc[0,'startYear'])\n",
    "    end_year.append(group.reset_index().loc[0,'endYear'])\n",
    "    runtime.append(group.reset_index().loc[0,'runtimeMinutes'])\n",
    "    genres.append(group.reset_index().loc[0,'genres'])\n",
    "    avg_rating.append(group.reset_index().loc[0,'averageRating'])\n",
    "    num_votes.append(group.reset_index().loc[0,'numVotes'])\n",
    "    \n",
    "    imdb_df_new = pd.DataFrame(data= {'title':title, 'title_type':title_type, 'start_year':start_year, 'end_year':end_year,\n",
    "                                      'runtime_min':runtime, 'genres':genres, 'avg_rating':avg_rating, 'num_votes':num_votes,\n",
    "                                         'crew_job': crew_job, 'charachter_names':crew_name})\n",
    "    \n",
    "#     imdb_df[imdb_df['title']==key,'crew_job'] = crew_job\n",
    "#     imdb_df[imdb_df['title']==key,'character_name'] = crew_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imdb_df_new.shape)\n",
    "imdb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81723506",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df_new.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dfcd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(data={'crew_job':crew_job, 'character_name':crew_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_df.shape)\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f588c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "imdb_df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bbd8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imdb_df = pd.merge(df, imdb_df_new, how='left', on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d73f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imdb_df = merged_imdb_df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320745aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_imdb_df.shape)\n",
    "merged_imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524cd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "akas_df = pd.read_csv('title.akas.tsv/data.tsv', sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6969e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "akas_df = akas_df[akas_df['title'].isin(merged_imdb_df.title.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c88fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(akas_df.shape)\n",
    "print(akas_df.title.nunique())\n",
    "akas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fab9f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "akas_df['language'] = akas_df['language'].apply(lambda x : random.choice(akas_df['language'].unique()) if x=='\\\\N' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42eff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "akas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174abf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# akas_df['language'] = akas_df['language'].fillna(random.choice(akas_df['language'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b49ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in akas_df.iterrows():\n",
    "    if row['language'] == None:\n",
    "        akas_df.loc[index, 'language'] = random.choice(akas_df['language'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc40ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "akas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a09ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "akas_df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be6da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "akas_df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_group = akas_df.groupby('title')\n",
    "title_list = []\n",
    "language_list = []\n",
    "for key, group in title_group:\n",
    "    if group.reset_index().loc[0,'language'] != None:\n",
    "        title_list.append(group.reset_index().loc[0,'title'])\n",
    "        language_list.append(group.reset_index().loc[0,'language'])\n",
    "        pass\n",
    "akas_new_df = pd.DataFrame(data={'title':title_list, 'language':language_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7491f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "akas_new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "akas_new_df.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faec5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "akas_new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e32c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imdb_df_new = pd.merge(merged_imdb_df, akas_new_df, how='left', on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c559d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imdb_df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imdb_df_new.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b962dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imdb_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imdb_df_new.to_csv('generated_data/imdb_subset_generated_data_merged_with_lang_genre.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84eea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('titles - ', merged_imdb_df_new.title.nunique())\n",
    "print('users - ', merged_imdb_df_new.user_id.nunique())\n",
    "print('languages - ', merged_imdb_df_new.language.nunique())\n",
    "print('Genre - ', merged_imdb_df_new.genres.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bc499",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imdb_df_new.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97770ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lan_list = ['en', 'fr', 'hi', 'uk', 'he']\n",
    "temp_df = merged_imdb_df_new[merged_imdb_df_new['language'].isin(lan_list)]\n",
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931cfb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_df.title.nunique())\n",
    "print(temp_df.user_id.nunique())\n",
    "temp_df.genres.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f68cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f26677",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.to_csv('demo_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbb3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(temp_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8423c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e7218",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('demo_data_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071bb880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
